{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd04e3844b72a7cf8ab0d3d9d1f66ba811b683ddb4d84051a42926a17d4fe42a429",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# EI ST4"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"DS_CentraleSupelec_ST42021/DS_CentraleSupelec_train.csv\")"
   ]
  },
  {
   "source": [
    "## Cleaning up the dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "source": [
    "Get unique count for each variable"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "source": [
    "Check variable data type"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "source": [
    "We can remove the `languageCode` and `countryCode` column as they are constant"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[~df.languageCode.isin(['fr', 'FR'])].empty and df[~df.countryCode.eq('FRA')].empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['languageCode', 'countryCode'])"
   ]
  },
  {
   "source": [
    "We will also remove the `registrationDate`, `reactivationValue`, `emailContactable` and `postalContactable` as they are irrelevant. `postalCode` as it will be to hard to analyse."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['registrationDate', 'reactivationValue', 'emailContactable', 'postalContactable', 'postalCode'])"
   ]
  },
  {
   "source": [
    "We are going to replace the `washDishes` `STRING` column with an `INT` column"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"washDishes\"] = df[\"washDishes\"].apply(lambda e: 1 if e == 'Auto' else -1)"
   ]
  },
  {
   "source": [
    "In the `MrPropreTrier`, `AntikalTrier`, `ArielTrier`, `DashTrier` we will replace `Known Trier` with `1` and `Nan` with `-1`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ['MrPropreTrier', 'AntikalTrier', 'ArielTrier', 'DashTrier']:\n",
    "    df[c[:-5]] = df.apply(lambda row: 1 if row[c] == 'Known Trier' else -1, axis=1)\n",
    "    df = df.drop(columns=[c])"
   ]
  },
  {
   "source": [
    "We will replace `detergentType` by `liquid`, `pods` and `powder` "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pods\n",
    "df['pods'] = df['detergentType'].apply(lambda e: 1 if pd.notna(e) and 'Pods' in e else -1)\n",
    "\n",
    "# powder\n",
    "df['powder'] = df['detergentType'].apply(lambda e: 1 if pd.notna(e) and 'Powder' in e else -1)\n",
    "\n",
    "# liquid\n",
    "df['liquid'] = df['detergentType'].apply(lambda e: 1 if pd.notna(e) and 'Liquid' in e else -1)\n",
    "\n",
    "# removes extra column\n",
    "df = df.drop(columns=['detergentType']) "
   ]
  },
  {
   "source": [
    "Replacing `toothBrushType` with `electricToothbrush`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['electricToothbrush'] = df.apply(lambda row: 1 if row['toothBrushType'] == 'Electric' else -1, axis=1)\n",
    "df = df.drop(columns=['toothBrushType'])"
   ]
  },
  {
   "source": [
    "Replacing `petOwner` with `hasPet`, if the first 3 characters are 'Yes' or 'Oui' the value is `1`, else it is `-1`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likesPets(s:str) -> float:\n",
    "    if s in ['Yes, we love our furry friends', \"Oui, j'adore nos petites boules de poils !\"]: \n",
    "        return 1\n",
    "\n",
    "    if s in ['Yes']: \n",
    "        return 0.9\n",
    "\n",
    "    if s in [\"Non, j'aime les animaux, mais je n'en ai pas pour le moment.\", 'No, we love animals but no pets here for now']:   \n",
    "        return 0.8\n",
    "    \n",
    "    if s in ['No - maybe future']:\n",
    "        return 0.5\n",
    "\n",
    "    if s in ['No']:\n",
    "        return 0.3\n",
    "\n",
    "    if s in ['Des animaux dans la maison ? Non merci !', \"No, we'd never have pets in the house\"]:\n",
    "        return 0\n",
    "\n",
    "# creating a new column for animal lovers\n",
    "df['likesPets'] = df['petOwner'].apply(likesPets)\n",
    "\n",
    "# creating a new column for pet owners\n",
    "df['hasPet'] = df['petOwner'].apply(lambda e: 1 if str(e)[:3] == 'Yes' or str(e)[:3] == 'Oui' else -1)\n",
    "\n",
    "df = df.drop(columns=['petOwner'])"
   ]
  },
  {
   "source": [
    "Transforms a `ISO 8601` time string to the amount of days since the time string"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeStringToDelta(timeString: str) -> int:\n",
    "    if pd.isna(timeString): return None\n",
    "    return int((datetime.utcnow().timestamp() - datetime.strptime(timeString[:10], \"%Y-%m-%d\").timestamp()) / 3600 / 24)"
   ]
  },
  {
   "source": [
    "Replaces `lastActivityDate` with `daysSinceActivity`: an `integer` representing the amount of ellapsed days since last activity"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['daysSinceActivity'] = df['lastActivityDate'].apply(timeStringToDelta)\n",
    "\n",
    "# normalizess the new column\n",
    "minV = df['daysSinceActivity'].min()\n",
    "maxV = df['daysSinceActivity'].max()\n",
    "df['daysSinceActivity'] = df['daysSinceActivity'].apply(lambda e: (e - minV) / (maxV - minV))\n",
    "\n",
    "# replaces Nan by the avg\n",
    "df['daysSinceActivity'].fillna(df['daysSinceActivity'].mean(skipna=True))\n",
    "\n",
    "# removes the extra column\n",
    "df = df.drop(columns=['lastActivityDate'])"
   ]
  },
  {
   "source": [
    "Replaces `age` with a normalized column"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizess the new column\n",
    "minV = df['age'].min()\n",
    "maxV = df['age'].max()\n",
    "df['age'] = df['age'].apply(lambda e: (e - minV) / (maxV - minV))\n",
    "\n",
    "# replaces Nan by the avg\n",
    "df['age'].fillna(df['age'].mean(skipna=True))"
   ]
  },
  {
   "source": [
    "The possible values for `numberChildren` are `'1'`, `'2'`, `'3'`, `'4'`, `'4+'` and `'NaN'`. We will be creating a column `nbChildren` of type `int` where `'NaN'` will be mapped to `None`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def childrenMagik(children: str) -> float:\n",
    "    if children == '0': return 0\n",
    "    if children == '1': return 1 / 5\n",
    "    if children == '2': return 2 / 5\n",
    "    if children == '3': return 3 / 5\n",
    "    if children == '4': return 4 / 5\n",
    "    if children == '4+': return 1\n",
    "    return None\n",
    "\n",
    "df['nbChildren'] = df['numberChildren'].apply(childrenMagik)\n",
    "\n",
    "# Replacing nan with the avg\n",
    "df['nbChildren'] = df['nbChildren'].fillna(df['nbChildren'].mean(skipna=True))\n",
    "\n",
    "df = df.drop(columns=['numberChildren'])"
   ]
  },
  {
   "source": [
    "Replaces `F` with `1` and `M` with `-1` in the `gender` column"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'] = df['gender'].apply(lambda e: 1 if e == \"F\" else -1)"
   ]
  },
  {
   "source": [
    "Changes `ecoInterest` replacing `High`, `Medium`, `Low`, `Very high` with a scale going from `0` to `1`. We the replace `nan` with the avg."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textScaleToFloat(s:str) -> float:\n",
    "    if s == 'Very high': return 1\n",
    "    if s == 'High': return 2 / 3\n",
    "    if s == 'Medium': return 1 / 3\n",
    "    if s == 'Low': return 0\n",
    "    return None\n",
    "\n",
    "# replaces the 'normal' values with floats\n",
    "df['ecoInterest'] = df['ecoInterest'].apply(textScaleToFloat)\n",
    "\n",
    "# replaces the nan with the avg\n",
    "df['ecoInterest'] = df['ecoInterest'].fillna(df['ecoInterest'].mean(skipna=True))"
   ]
  },
  {
   "source": [
    "Changes `scentLover` replacing `NonUser`, `Low`, `Medium`, `High` with a scale going from 0 to 1. We the replace `nan` with the avg."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textScaleToFloat(s:str) -> float:\n",
    "    if s == 'High': return 1\n",
    "    if s == 'Medium': return 2 / 3\n",
    "    if s == 'Low': return 1 / 3\n",
    "    if s == 'NonUser': return 0\n",
    "    return None\n",
    "\n",
    "# replaces the 'normal' values with floats\n",
    "df['scentLover'] = df['scentLover'].apply(textScaleToFloat)\n",
    "\n",
    "# replaces the nan with the avg\n",
    "df['scentLover'] = df['scentLover'].fillna(df['scentLover'].mean(skipna=True))"
   ]
  },
  {
   "source": [
    "Handles the closest shop"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['magasin']           = df['closestShop'].apply(lambda e: 1 if e =='1. Magasin de Proximit�' else -1)\n",
    "df['moyenneSurface']    = df['closestShop'].apply(lambda e: 1 if e =='2. Moyenne Surface' else -1)\n",
    "df['superMarket']       = df['closestShop'].apply(lambda e: 1 if e =='3. SuperMarket' else -1)\n",
    "df['hyperMarket']       = df['closestShop'].apply(lambda e: 1 if e =='4. HyperMarket' else -1)\n",
    "df['drive']             = df['closestShop'].apply(lambda e: 1 if e =='5. Drive' else -1)\n",
    "df['hardDiscount']      = df['closestShop'].apply(lambda e: 1 if e =='6. Hard Discounter' else -1)\n",
    "\n",
    "# removes extra column\n",
    "df = df.drop(columns=['closestShop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./DS_CentraleSupelec_ST42021/clean.csv')  "
   ]
  },
  {
   "source": [
    "# Using consumeractions data set\n",
    "\n",
    "In order to have more information about customers, we are going to add features, using the data set \"consumer actions\"\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's get the csv consumer_actions\n",
    "df_consumer_actions = pd.read_csv(r\"DS_CentraleSupelec_ST42021/DS_CentraleSupelec_consumeractions.csv\")\n",
    "\n",
    "#Let's check the possible values for 'event'\n",
    "df_consumer_actions.event.unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consumer_actions.brandName.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### First step : we will determine if a user has had an action related to the product 'Fairy PEPS'. We have seen in the list of brands that Fairy PEPS can be written 'Fairy PEPS Platinum+ Tout-en-1' or 'Fairy PEPS Tout-en-1 Plus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's create target text\n",
    "target_brand1 = 'Fairy PEPS Platinum+ Tout-en-1'\n",
    "target_brand2 = 'Fairy PEPS Tout-en-1 Plus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to test if the brandName related to each action is Fairy PEPS\n",
    "bool1 = df_consumer_actions['brandName']== target_brand1\n",
    "bool2 = df_consumer_actions['brandName']== target_brand2\n",
    "bool3 = df_consumer_actions['brandName2']== target_brand1\n",
    "bool4 = df_consumer_actions['brandName2']== target_brand2\n",
    "\n",
    "df_consumer_actions['brandName_bool'] = bool1 | bool2\n",
    "df_consumer_actions['brandName2_bool'] = bool3 | bool4 \n",
    "\n",
    "#Let's create a new column for each row telling us if the brandname 1 or 2 of the email was FairyPEPS\n",
    "df_consumer_actions['brand'] = df_consumer_actions['brandName_bool'] | df_consumer_actions['brandName2_bool']\n",
    "#We want it in the 1 or -1 format\n",
    "df_consumer_actions['brand'] = df_consumer_actions.apply(lambda row: 1 if row['brand'] else -1, axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to evaluate to level of interest of each user about the emails, coupons or products of P&G depending on their action\n",
    "\n",
    "def levelOfInterestAboutMarketing(action: str) -> float:\n",
    "    if action == 'Email Opened': return 1/5\n",
    "    if action == 'Email Clicked': return 2/5\n",
    "    if action == 'Search Site': return 3/5\n",
    "    if action == 'Product Reviewed': return 4/5\n",
    "    if action == 'Request Coupon Print': return 1\n",
    "    if action == 'Request Coupon Add To Basket': return 1\n",
    "    if action == 'Coupon Redemption': return 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    return None\n",
    "\n",
    "df_consumer_actions['level_of_interest_about_marketing'] = df_consumer_actions['event'].apply(levelOfInterestAboutMarketing)\n",
    "df_consumer_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As each user appears several time, we have to group by userId the rows and apply aggregate functions. It allows us to get a new information : the number of actions done by an user. It requires two groupby and a merge of the two results.\n",
    "df_consumer_actions_cleaned_one = df_consumer_actions.groupby(['userId'], sort=False, as_index=False)[\"brand\",'level_of_interest_about_marketing'].max()\n",
    "df_consumer_actions_cleaned_two = df_consumer_actions.groupby(['userId'], sort=False, as_index=False)['event'].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_consumer_actions_cleaned = df_consumer_actions_cleaned_one.merge(df_consumer_actions_cleaned_two, left_on ='userId', right_on='userId',  how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The number of action is an integer : we have to scale it from 0 to 1\n",
    "minV = df_consumer_actions_cleaned['event'].min()\n",
    "maxV = df_consumer_actions_cleaned['event'].max()\n",
    "df_consumer_actions_cleaned['event'] = df_consumer_actions_cleaned['event'].apply(lambda e: (e - minV) / (maxV - minV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's check the results\n",
    "df_consumer_actions_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the column \"brand\" should be renamed to be more relevant\n",
    "df_consumer_actions_cleaned = df_consumer_actions_cleaned.rename(columns = {\"brand\" : \"interested_by_fairypeps_email\", \"event\": \"number_of_actions\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consumer_actions_cleaned"
   ]
  },
  {
   "source": [
    "#Let's add the new columns, gotten in consumeractions, to the initial DataFrame \n",
    "df_merged = df.merge(df_consumer_actions_cleaned, left_on ='userId', right_on='userId',  how='left')\n",
    "print(df.shape)\n",
    "print(df_consumer_actions_cleaned.shape)\n",
    "print(df_merged.shape)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's check the result\n",
    "df_merged"
   ]
  },
  {
   "source": [
    "Finally, we don't need anymore the column userId which is not useful for the algorithms"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We do not need the other columns and the userId\n",
    "df_merged =  df_merged.drop(columns=['userId'])\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reindexing of the columns to have washDishes on the last column\n",
    "\n",
    "df_merged = df_merged.reindex(columns=[\n",
    "'userId',\n",
    "'age',\n",
    "'gender',\n",
    "'scentLover',\n",
    "'ecoInterest',\n",
    "'MrPropre',\n",
    "'Antikal',\n",
    "'Ariel',\n",
    "'Dash',\n",
    "'pods',\n",
    "'powder',\n",
    "'liquid',\n",
    "'electricToothbrush',\n",
    "'likesPets',\n",
    "'hasPet',\n",
    "'daysSinceActivity',\n",
    "'nbChildren',\n",
    "'magasin',\n",
    "'moyenneSurface',\n",
    "'superMarket',\n",
    "'hyperMarket',\n",
    "'drive',\n",
    "'hardDiscount',\n",
    "'interested_by_fairypeps_email',\n",
    "'level_of_interest_about_marketing',\n",
    "'number_of_actions',\n",
    "'washDishes',])\n",
    "\n",
    "df_train = df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The final result is..\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}