{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd07a63f3d33346feb89396e44d2106d71a898db4d716a84ec7a90cd4a8106e1c30",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Gradient Boosting Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\tekadvice\\anaconda3\\lib\\site-packages (1.4.2)\nRequirement already satisfied: numpy in c:\\users\\tekadvice\\anaconda3\\lib\\site-packages (from xgboost) (1.18.5)\nRequirement already satisfied: scipy in c:\\users\\tekadvice\\anaconda3\\lib\\site-packages (from xgboost) (1.5.0)\n"
     ]
    }
   ],
   "source": [
    "%run cleanData.ipynb\n",
    "%run cleanData_test.ipynb\n",
    "\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert data into float to be used in our algorithm\n",
    "\n",
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float64)\n",
    "\n",
    "df_train=clean_dataset(df_train)\n",
    "df_test =clean_dataset(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are using 80-20 split for train-test\n",
    "VALID_SIZE = 0.2\n",
    "#We also use random state for reproducibility\n",
    "RANDOM_STATE = 2018\n",
    "\n",
    "train, valid = train_test_split(df_train, test_size=VALID_SIZE, random_state=RANDOM_STATE, shuffle=True )"
   ]
  },
  {
   "source": [
    "We're going to split the data between predictors and target"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['age',\n",
    "'gender',\n",
    "'scentLover',\n",
    "'ecoInterest',\n",
    "'MrPropre',\n",
    "'Antikal',\n",
    "'Ariel',\n",
    "'Dash',\n",
    "'pods',\n",
    "'powder',\n",
    "'liquid',\n",
    "'electricToothbrush',\n",
    "'likesPets',\n",
    "'hasPet',\n",
    "'daysSinceActivity',\n",
    "'nbChildren',\n",
    "'magasin',\n",
    "'moyenneSurface',\n",
    "'superMarket',\n",
    "'hyperMarket',\n",
    "'drive',\n",
    "'hardDiscount']\n",
    "target = 'washDishes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train[predictors]\n",
    "train_Y = train[target].values\n",
    "valid_X = valid[predictors]\n",
    "valid_Y = valid[target].values"
   ]
  },
  {
   "source": [
    "We're going to test the algorithm with different learning rates:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_list = [0.1, 0.25, 0.5, 0.75, 1]\n",
    "# no_estimators_list = [100, 200, 300, 400, 500, 600]\n",
    "\n",
    "# bestScore = 0\n",
    "# bestParams = (0,0)\n",
    "\n",
    "# for lr in lr_list:\n",
    "#     for n in no_estimators_list:\n",
    "#         clf = GradientBoostingClassifier(n_estimators = n, learning_rate = lr)\n",
    "#         clf.fit(train_X, train_Y)\n",
    "\n",
    "#         print(\"Learning rate:\", lr)\n",
    "#         print(\"Number of estimators:\", n)\n",
    "#         print(\"Accuracy (training): {0:.3f}\".format(clf.score(train_X, train_Y)))\n",
    "#         print(\"Accuracy (validation): {0:.3f}\".format(clf.score(valid_X, valid_Y)))\n",
    "\n",
    "#         if clf.score(valid_X, valid_Y) > bestScore:\n",
    "#             bestScore = clf.score(valid_X, valid_Y)\n",
    "#             bestParams = (lr, n)\n",
    "\n",
    "# print(\"The best score (validation accuracy) is:\", bestScore)\n",
    "# print(\"Parameters (learning rate, nb of estimators):\", bestParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-33-2a496e84dfd2>, line 5)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-33-2a496e84dfd2>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    print(\"Validation accuracy:\" score)\u001b[0m\n\u001b[1;37m                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier()\n",
    "xgb_clf.fit(train_X, train_Y)\n",
    "\n",
    "score = xgb_clf.score(valid_X, valid_Y)\n",
    "print(\"Validation accuracy:\", score)"
   ]
  }
 ]
}