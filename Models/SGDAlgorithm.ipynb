{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd04e3844b72a7cf8ab0d3d9d1f66ba811b683ddb4d84051a42926a17d4fe42a429",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import of the clean data from the train_dataset and the test_dataset\n",
    "df_train= pd.read_csv(r'../Data/train.csv')\n",
    "df_test= pd.read_csv(r'../Data/test.csv')\n",
    "\n",
    "df_train = df_train.drop(columns=['userId'])\n",
    "df_test = df_test.drop(columns=['userId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert data into float to be used in our algorithm\n",
    "\n",
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float64)\n",
    "\n",
    "df_train=clean_dataset(df_train)\n",
    "df_test =clean_dataset(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are using 80-20 split for train-test\n",
    "VALID_SIZE = 0.2\n",
    "#We also use random state for reproducibility\n",
    "RANDOM_STATE = 2018\n",
    "\n",
    "train, valid = train_test_split(df_train, test_size=VALID_SIZE, random_state=RANDOM_STATE, shuffle=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            age  gender  scentLover  ecoInterest  washDishes  MrPropre  \\\n",
       "0      0.077922     1.0    0.000000     0.388626         1.0      -1.0   \n",
       "1      0.636364     1.0    0.378981     0.666667         1.0       1.0   \n",
       "2      0.350649     1.0    0.000000     0.666667         1.0      -1.0   \n",
       "3      0.220779     1.0    0.333333     0.333333        -1.0      -1.0   \n",
       "4      0.259740     1.0    0.378981     0.000000        -1.0       1.0   \n",
       "...         ...     ...         ...          ...         ...       ...   \n",
       "11995  0.454545     1.0    0.378981     0.388626         1.0      -1.0   \n",
       "11996  0.324675     1.0    0.333333     0.333333        -1.0      -1.0   \n",
       "11997  0.311688     1.0    0.378981     0.666667        -1.0      -1.0   \n",
       "11998  0.272727    -1.0    0.378981     0.388626         1.0      -1.0   \n",
       "11999  0.181818     1.0    0.000000     0.666667        -1.0      -1.0   \n",
       "\n",
       "       Antikal  Ariel  Dash  pods  ...  likesPets  hasPet  daysSinceActivity  \\\n",
       "0         -1.0   -1.0  -1.0  -1.0  ...        0.9     1.0           0.234694   \n",
       "1          1.0    1.0  -1.0   1.0  ...        0.3    -1.0           0.014914   \n",
       "2         -1.0    1.0   1.0  -1.0  ...        0.9     1.0           0.094976   \n",
       "3         -1.0    1.0   1.0   1.0  ...        0.9     1.0           0.259812   \n",
       "4          1.0    1.0   1.0  -1.0  ...        0.9     1.0           0.116954   \n",
       "...        ...    ...   ...   ...  ...        ...     ...                ...   \n",
       "11995     -1.0   -1.0  -1.0   1.0  ...        0.9     1.0           0.000785   \n",
       "11996     -1.0   -1.0  -1.0  -1.0  ...        0.9     1.0           0.124019   \n",
       "11997     -1.0   -1.0  -1.0  -1.0  ...        0.9     1.0           0.018838   \n",
       "11998     -1.0   -1.0  -1.0  -1.0  ...        0.9     1.0           0.197017   \n",
       "11999     -1.0   -1.0  -1.0  -1.0  ...        0.9     1.0           0.220565   \n",
       "\n",
       "       nbChildren  magasin  moyenneSurface  superMarket  hyperMarket  drive  \\\n",
       "0             0.2     -1.0            -1.0         -1.0         -1.0   -1.0   \n",
       "1             0.6     -1.0            -1.0         -1.0         -1.0   -1.0   \n",
       "2             0.2     -1.0            -1.0         -1.0         -1.0   -1.0   \n",
       "3             0.4     -1.0            -1.0         -1.0         -1.0   -1.0   \n",
       "4             0.0     -1.0            -1.0         -1.0         -1.0   -1.0   \n",
       "...           ...      ...             ...          ...          ...    ...   \n",
       "11995         1.0     -1.0            -1.0         -1.0         -1.0   -1.0   \n",
       "11996         0.0     -1.0            -1.0         -1.0         -1.0   -1.0   \n",
       "11997         0.6     -1.0            -1.0         -1.0         -1.0   -1.0   \n",
       "11998         0.2     -1.0            -1.0         -1.0         -1.0   -1.0   \n",
       "11999         0.6     -1.0            -1.0          1.0         -1.0   -1.0   \n",
       "\n",
       "       hardDiscount  \n",
       "0              -1.0  \n",
       "1              -1.0  \n",
       "2              -1.0  \n",
       "3              -1.0  \n",
       "4              -1.0  \n",
       "...             ...  \n",
       "11995          -1.0  \n",
       "11996          -1.0  \n",
       "11997          -1.0  \n",
       "11998          -1.0  \n",
       "11999          -1.0  \n",
       "\n",
       "[12000 rows x 23 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>gender</th>\n      <th>scentLover</th>\n      <th>ecoInterest</th>\n      <th>washDishes</th>\n      <th>MrPropre</th>\n      <th>Antikal</th>\n      <th>Ariel</th>\n      <th>Dash</th>\n      <th>pods</th>\n      <th>...</th>\n      <th>likesPets</th>\n      <th>hasPet</th>\n      <th>daysSinceActivity</th>\n      <th>nbChildren</th>\n      <th>magasin</th>\n      <th>moyenneSurface</th>\n      <th>superMarket</th>\n      <th>hyperMarket</th>\n      <th>drive</th>\n      <th>hardDiscount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.077922</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.388626</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>...</td>\n      <td>0.9</td>\n      <td>1.0</td>\n      <td>0.234694</td>\n      <td>0.2</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.636364</td>\n      <td>1.0</td>\n      <td>0.378981</td>\n      <td>0.666667</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.3</td>\n      <td>-1.0</td>\n      <td>0.014914</td>\n      <td>0.6</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.350649</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.666667</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>...</td>\n      <td>0.9</td>\n      <td>1.0</td>\n      <td>0.094976</td>\n      <td>0.2</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.220779</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.9</td>\n      <td>1.0</td>\n      <td>0.259812</td>\n      <td>0.4</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.259740</td>\n      <td>1.0</td>\n      <td>0.378981</td>\n      <td>0.000000</td>\n      <td>-1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>...</td>\n      <td>0.9</td>\n      <td>1.0</td>\n      <td>0.116954</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11995</th>\n      <td>0.454545</td>\n      <td>1.0</td>\n      <td>0.378981</td>\n      <td>0.388626</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.9</td>\n      <td>1.0</td>\n      <td>0.000785</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>11996</th>\n      <td>0.324675</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>...</td>\n      <td>0.9</td>\n      <td>1.0</td>\n      <td>0.124019</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>11997</th>\n      <td>0.311688</td>\n      <td>1.0</td>\n      <td>0.378981</td>\n      <td>0.666667</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>...</td>\n      <td>0.9</td>\n      <td>1.0</td>\n      <td>0.018838</td>\n      <td>0.6</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>11998</th>\n      <td>0.272727</td>\n      <td>-1.0</td>\n      <td>0.378981</td>\n      <td>0.388626</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>...</td>\n      <td>0.9</td>\n      <td>1.0</td>\n      <td>0.197017</td>\n      <td>0.2</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>11999</th>\n      <td>0.181818</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.666667</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>...</td>\n      <td>0.9</td>\n      <td>1.0</td>\n      <td>0.220565</td>\n      <td>0.6</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>12000 rows × 23 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "source": [
    "First, we define the predictors variables, then the target variable to predict"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['age',\n",
    "'gender',\n",
    "'scentLover',\n",
    "'ecoInterest',\n",
    "'MrPropre',\n",
    "'Antikal',\n",
    "'Ariel',\n",
    "'Dash',\n",
    "'pods',\n",
    "'powder',\n",
    "'liquid',\n",
    "'electricToothbrush',\n",
    "'likesPets',\n",
    "'hasPet',\n",
    "'daysSinceActivity',\n",
    "'nbChildren',\n",
    "'magasin',\n",
    "'moyenneSurface',\n",
    "'superMarket',\n",
    "'hyperMarket',\n",
    "'drive',\n",
    "'hardDiscount']\n",
    "target = 'washDishes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train[predictors]\n",
    "train_Y = train[target].values\n",
    "valid_X = valid[predictors]\n",
    "valid_Y = valid[target].values\n"
   ]
  },
  {
   "source": [
    "Implementation of Stochastic Gradient Descent Algorithm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf =  SGDClassifier(penalty=None)\n",
    "clf = SGDClassifier(penalty=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SGDClassifier(penalty=None)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "#Training of the model\n",
    "clf.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation of the model on the remaining 20% of the training set\n",
    "preds = clf.predict(valid_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2400,)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "source": [
    "Evaluation of our model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(train_X, train_Y)\n",
    "acc = round(clf.score(train_X, train_Y) * 100, 2)\n",
    "print(\"SGD accuracy (train set):\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf.score(valid_X, valid_Y)\n",
    "acc = round(clf.score(valid_X, valid_Y) * 100, 2)\n",
    "print(\"SGD accuracy (validation set):\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(valid_Y, preds, target_names=['Hand', 'Auto']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix():\n",
    "    cm = pd.crosstab(valid_Y, preds, rownames=['Actual'], colnames=['Predicted'])\n",
    "    fig, (ax1) = plt.subplots(ncols=1, figsize=(5,5))\n",
    "    sns.heatmap(cm, \n",
    "                xticklabels=['Hand', 'Auto'],\n",
    "                yticklabels=['Hand', 'Auto'],\n",
    "                annot=True,ax=ax1,\n",
    "                linewidths=.2,linecolor=\"Darkblue\", cmap=\"Blues\")\n",
    "    plt.title('Confusion Matrix', fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix()"
   ]
  },
  {
   "source": [
    "Let's initialize the GradientSearchCV parameters for optimization. We will set only few parameters, as following:\n",
    "\n",
    "n_estimators: number of trees in the foreset;\n",
    "\n",
    "max_features: max number of features considered for splitting a node;\n",
    "\n",
    "max_depth: max number of levels in each decision tree;\n",
    "\n",
    "min_samples_split: min number of data points placed in a node before the node is split;\n",
    "\n",
    "min_samples_leaf: min number of data points allowed in a leaf node."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#Finding best parameters for our SVC model\n",
    "\n",
    "parameters = {\n",
    "    'C': [0.1,0.2,0.3],\n",
    "    'kernel':['linear', 'rbf'],\n",
    "    'gamma' :[0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "#We initialize GridSearchCV with the classifier, the set of parameters, number of folds and also the level of verbose for printing out progress.\n",
    "\n",
    "grid_sgd = GridSearchCV(clf, parameters, scoring='accuracy', cv=10)\n",
    "grid_sgd.fit(train_X, train_Y)\n",
    "\n",
    "print('Best scores:',grid_sgd.best_score_)\n",
    "print('Best params:',grid_sgd.best_params_)\n",
    "\n",
    "\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's run our SVC again with the best parameters.\n",
    "sgd2 = SGD(C = 1.2, gamma =  0.9, kernel= 'rbf')\n",
    "sgd2.fit(train_X, train_Y)\n",
    "pred_sgd2 = sgd2.predict(valid_X)"
   ]
  },
  {
   "source": [
    "sgd2.score(valid_X, valid_Y)\n",
    "acc = round(sgd2.score(valid_X, valid_Y) * 100, 2)\n",
    "print(\"SGD accuracy optimized (validation set):\", acc)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "print(metrics.classification_report(valid_Y, preds, target_names=['Hand', 'Auto']))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "Use of our model in the test dataset to submit on Kaggle"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "prediction_test = gs_clf.predict(df_test)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "prediction_test[:10]"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "#As we have drop the userId column, we have to add it again next to the predicted values for the column \"washDishes\" so we get the userId again from the data set test.\n",
    "df_test_full = pd.read_csv(r\"DS_CentraleSupelec_ST42021/DS_CentraleSupelec_test.csv\")"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "result_prediction = pd.DataFrame(prediction_test, columns =['WashDishes'])"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "result_prediction['WashDishes']"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we have drop the userId column, we have to add it again next to the predicted values for the column \"washDishes\" so we get the userId again from the data set test.\n",
    "df_test_full = pd.read_csv(r'../Data/test.csv')"
   ]
  },
  {
   "source": [
    "submit = pd.concat([df_test_full['userId'],result_prediction['WashDishes']], axis=1)\n",
    "submit.shape"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "submit"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "#Formatting the submit data to fit the submission format expected by Kaggle.\n",
    "submit.rename(columns={\"washDishes\": \"WashDishes\"})\n",
    "\n",
    "submit['WashDishes'] = submit['WashDishes'].apply(lambda e: 'Auto' if e == 1 else 'Hand')\n",
    "submit"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "submit.to_csv('../DS_CentraleSupelec_ST42021/submit_SGD.csv', index=False)  "
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}