{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd04e3844b72a7cf8ab0d3d9d1f66ba811b683ddb4d84051a42926a17d4fe42a429",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run cleanData.ipynb\n",
    "%run cleanData_test.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert data into float to be used in our algorithm\n",
    "\n",
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float64)\n",
    "\n",
    "df_train=clean_dataset(df_train)\n",
    "df_test =clean_dataset(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are using 80-20 split for train-test\n",
    "VALID_SIZE = 0.2\n",
    "#We also use random state for reproducibility\n",
    "RANDOM_STATE = 2018\n",
    "\n",
    "train, valid = train_test_split(df_train, test_size=VALID_SIZE, random_state=RANDOM_STATE, shuffle=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "source": [
    "First, we define the predictors variables, then the target variable to predict"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['age',\n",
    "'gender',\n",
    "'scentLover',\n",
    "'ecoInterest',\n",
    "'MrPropre',\n",
    "'Antikal',\n",
    "'Ariel',\n",
    "'Dash',\n",
    "'pods',\n",
    "'powder',\n",
    "'liquid',\n",
    "'electricToothbrush',\n",
    "'likesPets',\n",
    "'hasPet',\n",
    "'daysSinceActivity',\n",
    "'nbChildren',\n",
    "'magasin',\n",
    "'moyenneSurface',\n",
    "'superMarket',\n",
    "'hyperMarket',\n",
    "'drive',\n",
    "'hardDiscount']\n",
    "target = 'washDishes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train[predictors]\n",
    "train_Y = train[target].values\n",
    "valid_X = valid[predictors]\n",
    "valid_Y = valid[target].values\n"
   ]
  },
  {
   "source": [
    "Implementation of Stochastic Gradient Descent Algorithm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf =  SGDClassifier(penalty=None)\n",
    "clf = SVC()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training of the model\n",
    "clf.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation of the model on the remaining 20% of the training set\n",
    "preds = clf.predict(valid_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In order to better understand the importance of each variable, we want to plot the features importance.\n",
    "def plot_feature_importance():\n",
    "    tmp = pd.DataFrame({'Feature': predictors, 'Feature importance': clf.feature_importances_})\n",
    "    tmp = tmp.sort_values(by='Feature importance',ascending=False)\n",
    "    plt.figure(figsize = (7,4))\n",
    "    plt.title('Features importance',fontsize=14)\n",
    "    s = sns.barplot(x='Feature',y='Feature importance',data=tmp)\n",
    "    s.set_xticklabels(s.get_xticklabels(),rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance()"
   ]
  },
  {
   "source": [
    "'daysSinceActivity' and 'Age' are the two most important features in the prediction."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Evaluation of our model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(train_X, train_Y)\n",
    "acc = round(clf.score(train_X, train_Y) * 100, 2)\n",
    "print(\"SGD accuracy (train set):\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf.score(valid_X, valid_Y)\n",
    "acc = round(clf.score(valid_X, valid_Y) * 100, 2)\n",
    "print(\"SGD accuracy (validation set):\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(valid_Y, preds, target_names=['Hand', 'Auto']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix():\n",
    "    cm = pd.crosstab(valid_Y, preds, rownames=['Actual'], colnames=['Predicted'])\n",
    "    fig, (ax1) = plt.subplots(ncols=1, figsize=(5,5))\n",
    "    sns.heatmap(cm, \n",
    "                xticklabels=['Hand', 'Auto'],\n",
    "                yticklabels=['Hand', 'Auto'],\n",
    "                annot=True,ax=ax1,\n",
    "                linewidths=.2,linecolor=\"Darkblue\", cmap=\"Blues\")\n",
    "    plt.title('Confusion Matrix', fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix()"
   ]
  },
  {
   "source": [
    "Let's initialize the GradientSearchCV parameters for optimization. We will set only few parameters, as following:\n",
    "\n",
    "n_estimators: number of trees in the foreset;\n",
    "\n",
    "max_features: max number of features considered for splitting a node;\n",
    "\n",
    "max_depth: max number of levels in each decision tree;\n",
    "\n",
    "min_samples_split: min number of data points placed in a node before the node is split;\n",
    "\n",
    "min_samples_leaf: min number of data points allowed in a leaf node."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#Finding best parameters for our SVC model\n",
    "\n",
    "parameters = {\n",
    "    'C': [0.8,1.3],\n",
    "    'kernel':['linear', 'rbf'],\n",
    "    'gamma' :[0.8, 1.3]\n",
    "}\n",
    "\n",
    "#We initialize GridSearchCV with the classifier, the set of parameters, number of folds and also the level of verbose for printing out progress.\n",
    "\n",
    "grid_svc = GridSearchCV(clf, parameters, scoring='accuracy', cv=10)\n",
    "grid_svc.fit(train_X, train_Y)\n",
    "\n",
    "print('Best scores:',grid_svc.best_score_)\n",
    "print('Best params:',grid_svc.best_params_)\n",
    "\n",
    "\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's run our SVC again with the best parameters.\n",
    "svc2 = SVC(C = 1.2, gamma =  0.9, kernel= 'rbf')\n",
    "svc2.fit(train_X, train_Y)\n",
    "pred_svc2 = svc2.predict(valid_X)\n",
    "print(classification_report(valid_Y, pred_svc2))"
   ]
  },
  {
   "source": [
    "svc2.score(valid_X, valid_Y)\n",
    "acc = round(svc2.score(valid_X, valid_Y) * 100, 2)\n",
    "print(\"SVC accuracy optimized (validation set):\", acc)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "print(metrics.classification_report(valid_Y, preds, target_names=['Hand', 'Auto']))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "Use of our model in the test dataset to submit on Kaggle"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "prediction_test = gs_clf.predict(df_test)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "prediction_test[:10]"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "#As we have drop the userId column, we have to add it again next to the predicted values for the column \"washDishes\" so we get the userId again from the data set test.\n",
    "df_test_full = pd.read_csv(r\"DS_CentraleSupelec_ST42021/DS_CentraleSupelec_test.csv\")"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "result_prediction = pd.DataFrame(prediction_test, columns =['WashDishes'])"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "result_prediction['WashDishes']"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "submit = pd.concat([df_test_full['userId'],result_prediction['WashDishes']], axis=1)\n",
    "submit.shape"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "submit"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "#Formatting the submit data to fit the submission format expected by Kaggle.\n",
    "submit.rename(columns={\"washDishes\": \"WashDishes\"})\n",
    "\n",
    "submit['WashDishes'] = submit['WashDishes'].apply(lambda e: 'Auto' if e == 1 else 'Hand')\n",
    "submit"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "submit.to_csv('./DS_CentraleSupelec_ST42021/submit_catboost.csv', index=False)  "
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}